{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-optimize) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-optimize) (0.22.1)\n",
      "Requirement already satisfied: pyaml in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-optimize) (19.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.3.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyaml->scikit-optimize) (5.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (45.2.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.34.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (1.18.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (1.3.1)\n",
      "Requirement already up-to-date: scikit-learn in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from lightgbm) (1.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (0.13.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.90)\n",
      "Requirement already satisfied: scipy in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from xgboost) (1.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\caioa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from xgboost) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize\n",
    "!pip install setuptools wheel numpy scipy\n",
    "!pip install -U scikit-learn\n",
    "!pip install lightgbm\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - xgboost=0.6a2\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/conda-forge/win-64\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/win-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/win-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge xgboost=0.6a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caioa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset Loading\n",
    "from sklearn.datasets import load_iris, make_friedman2, make_friedman1, make_regression\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "# Pre processing and manipulation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# metrics and hyperparameter optimization\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_error\n",
    "from skopt import dummy_minimize\n",
    "from skopt import gp_minimize\n",
    "\n",
    "# models\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "import lightgbm as lbm\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando as DBs\n",
    "db_teste = pd.read_csv(r'./test.csv')\n",
    "db_treino = pd.read_csv(r'./train.csv')\n",
    "db_teste_copy = db_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo DB e target \n",
    "X = db_treino.drop(['target', 'ID_code'], axis=1)\n",
    "y = db_treino['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199995</td>\n",
       "      <td>13.1678</td>\n",
       "      <td>1.0136</td>\n",
       "      <td>10.4333</td>\n",
       "      <td>6.7997</td>\n",
       "      <td>8.5974</td>\n",
       "      <td>-4.1641</td>\n",
       "      <td>4.8579</td>\n",
       "      <td>14.7625</td>\n",
       "      <td>-2.7239</td>\n",
       "      <td>6.9937</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>9.6849</td>\n",
       "      <td>4.6734</td>\n",
       "      <td>-1.3660</td>\n",
       "      <td>12.8721</td>\n",
       "      <td>1.2013</td>\n",
       "      <td>-4.6195</td>\n",
       "      <td>9.1568</td>\n",
       "      <td>18.2102</td>\n",
       "      <td>4.8801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199996</td>\n",
       "      <td>9.7171</td>\n",
       "      <td>-9.1462</td>\n",
       "      <td>7.3443</td>\n",
       "      <td>9.1421</td>\n",
       "      <td>12.8936</td>\n",
       "      <td>3.0191</td>\n",
       "      <td>5.6888</td>\n",
       "      <td>18.8862</td>\n",
       "      <td>5.0915</td>\n",
       "      <td>6.3545</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0071</td>\n",
       "      <td>6.6548</td>\n",
       "      <td>1.8197</td>\n",
       "      <td>2.4104</td>\n",
       "      <td>18.9037</td>\n",
       "      <td>-0.9337</td>\n",
       "      <td>2.9995</td>\n",
       "      <td>9.1112</td>\n",
       "      <td>18.1740</td>\n",
       "      <td>-20.7689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199997</td>\n",
       "      <td>11.6360</td>\n",
       "      <td>2.2769</td>\n",
       "      <td>11.2074</td>\n",
       "      <td>7.7649</td>\n",
       "      <td>12.6796</td>\n",
       "      <td>11.3224</td>\n",
       "      <td>5.3883</td>\n",
       "      <td>18.3794</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>5.7341</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1536</td>\n",
       "      <td>2.6498</td>\n",
       "      <td>2.4937</td>\n",
       "      <td>-0.0637</td>\n",
       "      <td>20.0609</td>\n",
       "      <td>-1.1742</td>\n",
       "      <td>-4.1524</td>\n",
       "      <td>9.1933</td>\n",
       "      <td>11.7905</td>\n",
       "      <td>-22.2762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199998</td>\n",
       "      <td>13.5745</td>\n",
       "      <td>-0.5134</td>\n",
       "      <td>13.6584</td>\n",
       "      <td>7.4855</td>\n",
       "      <td>11.2241</td>\n",
       "      <td>-11.3037</td>\n",
       "      <td>4.1959</td>\n",
       "      <td>16.8280</td>\n",
       "      <td>5.3208</td>\n",
       "      <td>8.9032</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4259</td>\n",
       "      <td>8.5012</td>\n",
       "      <td>2.2713</td>\n",
       "      <td>5.7621</td>\n",
       "      <td>17.0056</td>\n",
       "      <td>1.1763</td>\n",
       "      <td>-2.3761</td>\n",
       "      <td>8.1079</td>\n",
       "      <td>8.7735</td>\n",
       "      <td>-0.2122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199999</td>\n",
       "      <td>10.4664</td>\n",
       "      <td>1.8070</td>\n",
       "      <td>10.2277</td>\n",
       "      <td>6.0654</td>\n",
       "      <td>10.0258</td>\n",
       "      <td>1.0789</td>\n",
       "      <td>4.8879</td>\n",
       "      <td>14.4892</td>\n",
       "      <td>-0.5902</td>\n",
       "      <td>7.8362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>9.2828</td>\n",
       "      <td>1.3601</td>\n",
       "      <td>4.8985</td>\n",
       "      <td>20.0926</td>\n",
       "      <td>-1.3048</td>\n",
       "      <td>-2.5981</td>\n",
       "      <td>10.3378</td>\n",
       "      <td>14.3340</td>\n",
       "      <td>-7.7094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0    var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
       "0       11.0656   7.7798  12.9536  9.4292  11.4327  -2.3805  5.8493  18.2675   \n",
       "1        8.5304   1.2543  11.3047  5.1858   9.1974  -4.0117  6.0196  18.6316   \n",
       "2        5.4827 -10.3581  10.1407  7.0479  10.2628   9.8052  4.8950  20.2537   \n",
       "3        8.5374  -1.3222  12.0220  6.5749   8.8458   3.1744  4.9397  20.5660   \n",
       "4       11.7058  -0.1327  14.1295  7.7506   9.1035  -8.5848  6.8595  10.6048   \n",
       "...         ...      ...      ...     ...      ...      ...     ...      ...   \n",
       "199995  13.1678   1.0136  10.4333  6.7997   8.5974  -4.1641  4.8579  14.7625   \n",
       "199996   9.7171  -9.1462   7.3443  9.1421  12.8936   3.0191  5.6888  18.8862   \n",
       "199997  11.6360   2.2769  11.2074  7.7649  12.6796  11.3224  5.3883  18.3794   \n",
       "199998  13.5745  -0.5134  13.6584  7.4855  11.2241 -11.3037  4.1959  16.8280   \n",
       "199999  10.4664   1.8070  10.2277  6.0654  10.0258   1.0789  4.8879  14.4892   \n",
       "\n",
       "         var_8   var_9  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "0       2.1337  8.8100  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   \n",
       "1      -4.4131  5.9739  ...  10.6165   8.8349   0.9403  10.1282  15.5765   \n",
       "2       1.5233  8.3442  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   \n",
       "3       3.3755  7.4578  ...   9.5702   9.0766   1.6580   3.5813  15.1874   \n",
       "4       2.9890  7.1437  ...   4.2259   9.1723   1.2835   3.3778  19.5542   \n",
       "...        ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "199995 -2.7239  6.9937  ...   2.0544   9.6849   4.6734  -1.3660  12.8721   \n",
       "199996  5.0915  6.3545  ...   5.0071   6.6548   1.8197   2.4104  18.9037   \n",
       "199997  1.6603  5.7341  ...   5.1536   2.6498   2.4937  -0.0637  20.0609   \n",
       "199998  5.3208  8.9032  ...   3.4259   8.5012   2.2713   5.7621  17.0056   \n",
       "199999 -0.5902  7.8362  ...   0.1398   9.2828   1.3601   4.8985  20.0926   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "0        2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
       "1        0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2        2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3        3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
       "4       -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "199995   1.2013  -4.6195   9.1568  18.2102   4.8801  \n",
       "199996  -0.9337   2.9995   9.1112  18.1740 -20.7689  \n",
       "199997  -1.1742  -4.1524   9.1933  11.7905 -22.2762  \n",
       "199998   1.1763  -2.3761   8.1079   8.7735  -0.2122  \n",
       "199999  -1.3048  -2.5981  10.3378  14.3340  -7.7094  \n",
       "\n",
       "[200000 rows x 200 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_teste = db_teste.drop(['ID_code'], axis=1)\n",
    "db_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando treino e testes da DB e target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x147eed36bc8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotando a variável target para verificar se está balanceada\n",
    "y.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "#utilizando SMOTE para balancear as amostras\n",
    "%time\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14783ed8f88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAD7CAYAAAC47ukrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAZBUlEQVR4nO3de7Bd5Xnf8e9BFyxsBHYRkQgRDiV6kOMY2dxccyk1JBlFXJyJEUEKNxcRCjJmjJ1xxxJOG5ImbYINJHKIBBGNMCbFdkNiqaGmSXWoRw6XGhfZenBtIywkjahkoqLqitQ/1nukzeFIZ+vovHujw/czc4a1nvWuvd81m9k/vWut/a6ePXv2IElSDUd0uwOSpJHLkJEkVWPISJKqMWQkSdUYMpKkakZ3uwNvJk8//fSRwJnAOuC1LndHkg4Ho4BJwJOnn3769v4bDZnXOxPo7XYnJOkwdB7wRP+iIfN66wCmTJnC2LFju90XSXrT27FjB88//zyU78/+DJnXew1g7NixHHnkkd3uiyQdTga8xOCFf0lSNYaMJKkaQ0aSVI0hI0mqxpCRJFVjyEiSqjFkJEnVGDLDaMfO7sxE0633lTT8Rtr3iD/GHEZjx4ziktv+quPv+9d/dFnH31NSHSPte6RqyETEeOCbwMWZ+UJLfS7w0cy8oKxPBpYAxwMJzM7MVyPiWOBB4GTgZWBmZq6PiLHAfcAZwFZgVmauioge4D8AFwO7gTmZ+T9qHqMkaf+qnS6LiLNpJkub0q/+HuAz/ZovABZk5qnAU8D8Ur8D6M3MqcBC4K5SvwXYUuq3AotL/deAqcB7gI8AiyPC0ZokdUnNazJzgJuBtX2FiDgSuBe4vaU2BjgfeKSUFgOXl+UZNCMZgIeA6aX93npmLgcmlNHQDODLmbk7M58HXgQ+VOPgJEmDqxYymXl9ZvafNv/fAfcDP2ypHQdszsxdZX0dcGJZPqGsU7ZvBia01vvts7+6JKkLOnZ3WUT8IjA5M/98gD7s6VfbXf7b06/eU7b132ewuiSpCzp5C/OVwM9HxLeBRcAZEfEwsAE4JiJGlXaT2HeK7SVgIkC5tnI0sBFYU9r1mVj22V9dktQFHQuZzPxYZk7NzGnA9cBTmXlFZu6keRrlFaXp1cCysry0rFO295b2e+sRcS6wLTNfLPXZETEqIk6huengyQ4cniRpAG+WO69uAh6IiHk0F+uvLPX5NHeIrQReAWaX+j3AvaW+Hbiq1B8Bzga+U9b/ZWZu7UD/JUkDqB4ymfnuAWp/D1zQsr66db2lvgm4dID6NuCaAep7gE+VP0lSlzmtjCSpGkNGklSNISNJqsaQkSRVY8hIkqoxZCRJ1RgykqRqDBlJUjWGjCSpGkNGklSNISNJqsaQkSRVY8hIkqoxZCRJ1RgykqRqDBlJUjWGjCSpGkNGklSNISNJqsaQkSRVM7r2G0TEeOCbwMWZ+UJE3ADcAuwBngJ+MzN3RMQ0YBEwHlgO3JiZuyJiMrAEOB5IYHZmvhoRxwIPAicDLwMzM3N9RIwF7gPOALYCszJzVe3jlCS9UdWRTEScDTwBTCnrU4BPAx8C3lfe/+bSfAkwNzOnAD3AnFJfACzIzFNpQml+qd8B9GbmVGAhcFep3wJsKfVbgcW1jk+SdGC1T5fNoQmRtWV9O3BTZm7OzD3A/wImR8RJwLjMXFHaLQYuj4gxwPnAI631sjyDZiQD8BAwvbTfW8/M5cCEMhqSJHVY1dNlmXk9QET0ra8GVpfaBGAucC1wArCuZdd1wInAccDmzNzVr07rPuW02mZgwgFe68VhPThJ0qC6cuE/In4aeBy4LzP/vvRjT0uTHmD3AHVKva9Nq/3t09OyjySpgzoeMhFxKs2NAA9k5u+U8hpgUkuziTSn2DYAx0TEqFKfxL5Tby+VdkTEaOBoYOMBXkuS1GEdDZmIOBp4DJiXmX/UVy+n0bZFxDmldBWwLDN3Ar3AFaV+NbCsLC8t65TtvaX93npEnAtsy0xPlUlSF1S/hbmf64GfAm6LiNtK7dHMvB2YDSwstzw/A9xdtt8EPBAR82iuq1xZ6vOBxRGxEnil7A9wD3BvqW+nCSxJUhd0JGQy891l8fPlb6A2zwJnDVBfDVwwQH0TcOkA9W3ANUPvrSRpuPiLf0lSNYaMJKkaQ0aSVI0hI0mqxpCRJFVjyEiSqjFkJEnVGDKSpGoMGUlSNYaMJKkaQ0aSVI0hI0mqxpCRJFVjyEiSqjFkJEnVGDKSpGoMGUlSNYaMJKkaQ0aSVI0hI0mqZnTtN4iI8cA3gYsz84WIuAi4ExgHPJyZ80q7acAiYDywHLgxM3dFxGRgCXA8kMDszHw1Io4FHgROBl4GZmbm+ogYC9wHnAFsBWZl5qraxylJeqOqI5mIOBt4AphS1scB9wOXAVOBMyNiemm+BJibmVOAHmBOqS8AFmTmqcBTwPxSvwPozcypwELgrlK/BdhS6rcCi6sdoCTpgGqfLpsD3AysLetnAd/PzB9l5i6aYLk8Ik4CxmXmitJucamPAc4HHmmtl+UZNCMZgIeA6aX93npmLgcmlNGQJKnDqoZMZl6fmb0tpROAdS3r64ATD1A/DthcAqm1/rrXKts3AxMO8FqSpA7r9IX/I4A9Les9wO6DqFPqfW1aDfZakqQO63TIrAEmtaxPpDmVtr/6BuCYiBhV6pPYd+rtpdKOiBgNHA1sPMBrSZI6rNMh8y0gIuKUEhyzgGWZuRrYFhHnlHZXlfpOoBe4otSvBpaV5aVlnbK9t7TfW4+Ic4Ftmfli5eOSJA2goyGTmduAa4GvAN8FVrHvov5s4PMRsQp4B3B3qd8E3BAR3wXOA+aV+nzggxGxsrS5udTvAY4s9btpAkuS1AXVfycDkJnvbll+HDhtgDbP0tx91r++GrhggPom4NIB6tuAaw6pw5KkYeEv/iVJ1RgykqRqDBlJUjVthUxEfLzMQSZJUtvaHcm8D3g+IhZFxBk1OyRJGjnaCpnMnAP8HM0ElQsi4smI+FhEvK1q7yRJh7W2r8lk5v8F/hPwJeCf0PwuJSPikkp9kyQd5tq9JnNhRDwMPA+cCnwkM08HPgzcW7F/kqTDWLs/xvwTmue63JCZ/9hXzMwfRMTCKj2TJB32DubC/8bM/MeImBgRt0bEEQCZ+bl63ZMkHc7aDZk/Bi4uy7tp5hD7QpUeSZJGjHZD5kOZeSVAZm6geTrlv6jWK0nSiNBuyIyJiLEt6x2ZWFOSdHhrNyy+DvxtRPwFzVMnZ5WaJEn71W7IfJrmdzGXAbuAr+Kty5KkQbQVMpn5Gs0DwO4erK0kSX3aCpmI+AjN3WTvBHr66pnppJmSpP1q93TZHwCfBJ6huSYjSdKg2g2ZVzLzq1V7Ikkacdq9hflbETG9ak8kSSNOuyOZXwHmRsQOYAfNdZk9Q70mExG/AfzrsrosMz8VEdOARcB4YDlwY2buiojJwBLgeCCB2Zn5akQcCzwInAy8DMzMzPXl9zz3AWcAW4FZmblqKP2UJB2adkcyFwI/CwTwC8B7y38PWkQcRXOX2j8HTgPOi4iLaIJkbmZOoQmxOWWXBcCCzDyV5nk280v9DqA3M6cCC4G7Sv0WYEup3wosHko/JUmHrt2Hlq0GzqT54n+ZZpqZ1UN8z1Hlfd8OjCl/O4FxmbmitFkMXB4RY4DzgUda62V5Bs1IBuAhYHppv7eemcuBCWU0JEnqsHafJ/MZ4F8BM4FxwOciYv6B9xpYefjZfGAVsAZ4geYU3LqWZuuAE4HjgM2ZuatfHeCEvn3K9s3AhNb6APtIkjqo3dNlv05zXWZLZm4EPkgztcxBi4j3AR8DTqIJhNeAX+L1t0b30Mz2fARvvGV6d0ubVvvbp6dlH0lSB7UbMjszc3vfSma+QnOKayh+GXg8MzeU11wMXABMamkzEVgLbACOiYhRpT6p1AFeKu2IiNHA0cBGmtHRQK8lSeqwdkPmxxExA9gTEUdGxGeBoV6TeRa4KCLeHhE9wCXAfwe2RcQ5pc1VNHed7QR6gStK/WpgWVleWtYp23tL+731iDgX2JaZLw6xr5KkQ9DuLcxzgb+geULmFmAFMHsob5iZj0XE+4GnaUZD/wD8PvA1YGFEjKeZWaBvnrSbgAciYh7wInBlqc8HFkfESuCVlv7cA9xb6ttpAkuS1AXtTpC5Friw3H48qly8H7LM/AOaqWpaPQucNUDb1TSn0/rXNwGXDlDfBlxzKP2TJA2PdifI/GS/dQAy884KfZIkjRDtni5r/eHlWJofUj4+/N2RJI0k7Z4uu651PSJOoJm6RZKk/Wr37rLXKddo3j28XZEkjTRDuSbTQzP55IYqPZIkjRhDuSazh+ZW4k8Pf3ckSSPJkK7JSJLUjnZPl/0dB3jscmZ+eNh6JEkaMdo9XfYU8B7gz2hmTL667PvlSv2SJI0A7YbMucC5mfkaQET8LbAiM79SrWeSpMNeu7cwTwDe1rJ+NHDU8HdHkjSStDuS+RKwIiK+SnML80z2Pe5YkqQBtfv45duB24F30YxofjMzv1izY5Kkw9/B/OL/JeA5min2d9TpjiRpJGkrZCLiOuDPgd8CjgH+KiLm1OyYJOnw1+5I5uPAPwM2Z+YG4HTg1mq9kiSNCO2GzGuZublvJTN/DOyq0yVJ0kjRbshsiohplF/9R8RsYFO1XkmSRoR2b2H+BPAI8E8jYh2wFbisWq8kSSNCuyFzFHAaMAUYBWRm7hzqm0bEJcDngLcDj2XmJyLiIuBOYBzwcGbOK22nAYuA8cBy4MbM3BURk4ElwPFAArMz89WIOBZ4EDgZeBmYmZnrh9pXSdLQtXu67MHMfC0zv5eZzx1iwJwM/CnwEeB9wAciYjpwP83oaCpwZqlBEyRzM3MKzQ9B++5qWwAsyMxTaeZWm1/qdwC9mTkVWIg/GpWkrmk3ZL4TEbMiYnJEvKvvb4jv+as0I5U1JayuAP4f8P3M/FFm7qIJlssj4iRgXGauKPsuLvUxwPk0p/D21svyDJqRDMBDwPTSXpLUYe2eLruMfV/iffbQnDo7WKcAOyLiUWAy8DfASmBdS5t1wInACfupH0dzO/WufnVa9ymn1TbTzL22dgh9lSQdgnYfWva2wVsd1HueD1wAvAo8SnMjQevzanqA3TQjrXbqlHpfm1Y9LdskSR10wNNlEfFnLcvHDdN7rge+kZkvZ+ZW4GvARcCkljYTaUYea/ZT3wAcExF9I6lJ7BupvFTaERGjaWaM3jhMfZckHYTBrsmc0bL82DC9598AvxwRx5aQmE5zbSUi4pRSmwUsy8zVwLaIOKfse1Wp7wR6aa7nQPMQtWVleWlZp2zvPZQbFSRJQzdYyPTsZ3nIMvNbwL8HngC+C6wGvghcC3yl1Fax76L+bODzEbEKeAdwd6nfBNwQEd8FzgPmlfp84IMRsbK0uXk4+i1JOnjtXviHN14DGbLMvJ/mluVWj9P8Fqd/22eBswaor6a5rtO/vgm4dFg6Kkk6JIOFzBER8U6aUcyolmVg7xe6JEkDGixkfgH4P+wLltYL6EO9hVmS9BZxwJDJzIN5qJkkSa9jiEiSqjFkJEnVGDKSpGoMGUlSNYaMJKkaQ0aSVI0hI0mqxpCRJFVjyEiSqjFkJEnVGDKSpGoMGUlSNYaMJKkaQ0aSVI0hI0mqxpCRJFVjyEiSqhns8ctVRcQfAsdl5rURMQ1YBIwHlgM3ZuauiJgMLAGOBxKYnZmvRsSxwIPAycDLwMzMXB8RY4H7gDOArcCszFzV8YOTJHVvJBMRFwLXtJSWAHMzcwrQA8wp9QXAgsw8FXgKmF/qdwC9mTkVWAjcVeq3AFtK/VZgcc3jkCTtX1dCJiLeBfwu8Htl/SRgXGauKE0WA5dHxBjgfOCR1npZnkEzkgF4CJhe2u+tZ+ZyYEIZDUmSOqxbI5l7gc8CPynrJwDrWravA04EjgM2Z+aufvXX7VO2bwYmHOC1JEkd1vGQiYjrgR9n5uP9+rGnZb0H2D1AnVLva9Nqf/v0tOwjSeqgblz4vwKYFBHfBt4FvIMmFCa1tJkIrAU2AMdExKjMfK20WVvavFTarYmI0cDRwEZgTWn3g36vJUnqsI6PZDLzFzPzvZk5DbgdeDQzrwO2RcQ5pdlVwLLM3An00gQTwNXAsrK8tKxTtveW9nvrEXEusC0zX6x9XJKkN+rqLcz9zAYWRsR44Bng7lK/CXggIuYBLwJXlvp8YHFErAReKfsD3APcW+rbaQJLktQFXQ2ZzFxMucU4M58FzhqgzWrgggHqm4BLB6hv4/W3RkuSusRf/EuSqjFkJEnVGDKSpGoMGUlSNYaMJKkaQ0aSVI0hI0mqxpCRJFVjyEiSqjFkJEnVGDKSpGoMGUlSNYaMJKkaQ0aSVI0hI0mqxpCRJFVjyEiSqjFkJEnVGDKSpGoMGUlSNaO78aYR8TlgZln9emb+VkRcBNwJjAMezsx5pe00YBEwHlgO3JiZuyJiMrAEOB5IYHZmvhoRxwIPAicDLwMzM3N9Bw9PklR0fCRTwuSXgPcD04DTI+JK4H7gMmAqcGZETC+7LAHmZuYUoAeYU+oLgAWZeSrwFDC/1O8AejNzKrAQuKv+UUmSBtKN02XrgNsyc0dm7gS+B0wBvp+ZP8rMXTTBcnlEnASMy8wVZd/FpT4GOB94pLVelmfQjGQAHgKml/aSpA7reMhk5sq+0IiIn6M5bbabJnz6rANOBE7YT/04YHMJpNY6rfuU7ZuBCVUORpJ0QF278B8RPw/8V+DTwA+BPS2be2iC54g265R6X5tWPS3bJEkd1JWQiYhzgMeBz2TmA8AaYFJLk4nA2gPUNwDHRMSoUp9U6gAvlXZExGjgaGBjnSORJB1INy78/wzwn4FZmfnlUv5WsylOKcExC1iWmauBbSWUAK4q9Z1AL3BFqV8NLCvLS8s6ZXtvaS9J6rBu3ML8KeBtwJ0R0Vf7U+Ba4Ctl21L2XdSfDSyMiPHAM8DdpX4T8EBEzANeBK4s9fnA4ohYCbxS9pckdUHHQyYzPwF8Yj+bTxug/bPAWQPUVwMXDFDfBFx6aL2UJA0Hf/EvSarGkJEkVWPISJKqMWQkSdUYMpKkagwZSVI1howkqRpDRpJUjSEjSarGkJEkVWPISJKqMWQkSdUYMpKkagwZSVI1howkqRpDRpJUjSEjSarGkJEkVWPISJKqMWQkSdWM7nYHaoiIWcA8YAzwhcz8ky53SZLekkbcSCYifhr4XeBcYBpwQ0S8p7u9kqS3ppE4krkI+G+ZuQkgIh4BPgr82zb2HQWwY8eOIb/5sW8fNeR9h2r79u0df09J9RxO3yMt35cDdnokhswJwLqW9XXAWW3uOwng+eefH/Kb33rZpCHvO1TPPfdcx99TUj2H6ffIJOAH/YsjMWSOAPa0rPcAu9vc90ngPJpgem2Y+yVJI9EomoB5cqCNIzFk1tAERZ+JwNp2djz99NO3A0/U6JQkjWBvGMH0GYkh8w3gtyNiArAF+DXghu52SZLemkbc3WWZ+RLwWeDvgG8DX8rMf+huryTpralnz549g7eSJGkIRtxIRpL05mHISJKqMWQkSdUYMpKkakbiLczVDTYBZ0RMAxYB44HlwI2ZuavjHR0mbRzvZcC/ofnh64+A6zLzJx3v6DBqd5LViJgB/HFm/mwn+1dDG59zAPcC7wTWA78+0j/niPgAzTGPBX4M/EZmvtLxjg6ziBgPfBO4ODNf6LdtWL+/HMkcpDYn4FwCzM3MKTRfvHM628vhM9jxlv9ZvwjMyMzTgO8Av92Frg6bdidZjYifAv6Q5jM+rLXxOfcAjwK/Xz7n/wl8pht9HS5tfs53AbeXY07gU53t5fCLiLNpfnQ+ZT9NhvX7y5A5eHsn4MzMLUDfBJwARMRJwLjMXFFKi4HLO97L4XPA46X5F+DN5fdJ0ITM5A73cbgNdsx9FtGM4EaCwY75A8CWzPwvZf33gMP9ERrtfM6jaP5FD3AUsLWD/atlDnAzA8yEUuP7y9NlB2+wCTgH2n5iB/pVywGPNzM3Al8DiIhxNP+6vaeTHaxg0ElWI+IW4BlgBSPDYMd8CrA+Iu4D3g98D/h457pXRTuT6X4SeCwivkAzg8jZHepbNZl5PUBz9vMNhv37y5HMwRtsAs5DmaDzzait44mIY4CvA89m5gMd6lstBzzmiHgvzXRFv9PhftU02Oc8GrgA+GJmfgD4IXBnx3pXx2Cf8zjgPuCizJwELAD+Y0d72HnD/v1lyBy8NZRHAhT9J+AcbPvhZtDjiYhJQC/NqbLrO9e1agY75svL9qeApcAJEdHbue5VMdgxrwe+n5lPlfWHaP8RGm9Wgx3ze4GtLdNS3UsTtCPZsH9/GTIH7xvAhRExISKOovkXbd95ajJzNbAtIs4ppauAZZ3v5rA54PFGxCjgr4G/zMxbM3MkzFM02Gf8ucyckpnTgF8B1mbmeft5rcPFAY+Z5k6kCRFxWlm/BHi6w30cboMd8/8Gfib2nVe6jP1MZz9S1Pj+MmQO0v4m4IyIpRFxRmk2G/h8RKwC3gHc3Z3eHro2jvdSmovCH42Ib5e/RV3s8iFr8zMeUQY75szcCvwqsDAiVgIfBm7rXo8PXRvH/BPgWuAvI+I7wMeA67rW4Ypqfn85QaYkqRpHMpKkagwZSVI1howkqRpDRpJUjSEjSarGkJEkVWPISJKqMWQkSdX8fzoyCZOVZ+OYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#verificando o resultado\n",
    "y_train.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparando os modelos para verificar qual utilizar\n",
    "#isso demorou MUITO pra rodar\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# criando uma lista com todos os modelos\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "    #SVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier()]\n",
    "\n",
    "# criando uma funçào para rodas o pipeline \n",
    "for clf in classifiers:\n",
    "    # ajustando o modelo\n",
    "    clf.fit(X_train, y_train)\n",
    "    # armazenando o nome do modelo\n",
    "    name = clf.__class__.__name__\n",
    "    # imprimindo o nome do modelo\n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    # imprimindo os resultados\n",
    "    print('****Results****')\n",
    "    # fazendo predições\n",
    "    # calculando as métricas\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # imprimindo as métricas\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    143922\n",
       "0    143922\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scl',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=2,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                    ('clf', LogisticRegression())])\n",
    "pipe_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.786275"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_lr.predict(X_test)\n",
    "p = pipe_lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.786275\n",
      "Precision: 0.28707099200752234\n",
      "Recall: 0.7594527363184079\n",
      "F1 Score: 0.4166496076424428\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificando a documentação do LGBMClassifier\n",
    "?LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((287844, 200), (40000, 200), (287844,), (40000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#observando o shape de treinos e testes após SMOTE\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7743622769974475"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificando o resultado da AUC no dataset teste\n",
    "p = pipe_lr.predict(X_test)\n",
    "roc_auc_score(y_test, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "...   ..\n",
       "39995  0\n",
       "39996  0\n",
       "39997  0\n",
       "39998  1\n",
       "39999  0\n",
       "\n",
       "[40000 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_df = pd.DataFrame(p)\n",
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[9871.192514273254, 74, 768, 0.1717182255328889, 0.9991364637917304] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 39.2842\n",
      "Function value obtained: -0.7695\n",
      "Current minimum: -0.7695\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[296.604648999388, 3, 973, 0.4185152041039071, 0.7027714331231321] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 38.0878\n",
      "Function value obtained: -0.7738\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[7431.528396574379, 22, 255, 0.3476098410856614, 0.5720933436155843] \n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 40.3997\n",
      "Function value obtained: -0.7654\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[770.7362534461022, 30, 926, 0.5576932134996663, 0.9225658221213098] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 42.3564\n",
      "Function value obtained: -0.2339\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[821.1256449180222, 115, 504, 0.9421713999524446, 0.8005503127028802] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 45.9630\n",
      "Function value obtained: -0.2318\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[2703.591248314741, 9, 320, 0.13816076820870105, 0.5663372940477002] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 38.2199\n",
      "Function value obtained: -0.7897\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[5370.81884337239, 83, 265, 0.8381231914244746, 0.34574497679507266] \n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 42.2380\n",
      "Function value obtained: -0.5030\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[131.3670364396167, 74, 543, 0.6134122423831541, 0.704488687679921] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 42.9428\n",
      "Function value obtained: -0.2279\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[666.1557147664366, 5, 965, 0.3251481585185218, 0.22790812192746127] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 36.1736\n",
      "Function value obtained: -0.4878\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[3686.6248434672593, 82, 622, 0.0824627456265471, 0.661626987829618] \n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 37.7181\n",
      "Function value obtained: -0.5064\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[2095.421812724112, 27, 368, 0.47382778078180077, 0.2999120927818374] \n",
      "\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 39.6180\n",
      "Function value obtained: -0.7857\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[140.1936501796494, 24, 778, 0.1413636474231886, 0.9130331498309807] \n",
      "\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 38.1390\n",
      "Function value obtained: -0.2273\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[173.37278913742418, 29, 934, 0.12944185431967492, 0.9251752010767558] \n",
      "\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 37.6515\n",
      "Function value obtained: -0.2286\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[6620.59106509385, 12, 280, 0.6051696647010327, 0.6093208247177738] \n",
      "\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 41.4975\n",
      "Function value obtained: -0.7753\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[1689.9608181777878, 94, 587, 0.297930030634779, 0.30791387999133013] \n",
      "\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 38.3932\n",
      "Function value obtained: -0.4862\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[1166.5328715255023, 67, 370, 0.5184066138675086, 0.5865404579412796] \n",
      "\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 40.9269\n",
      "Function value obtained: -0.7846\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[3396.019762556291, 8, 565, 0.18296781323212874, 0.8131632272164173] \n",
      "\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 38.3804\n",
      "Function value obtained: -0.7768\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[114.7103794496559, 77, 264, 0.5637487801209164, 0.5031821632783764] \n",
      "\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 41.8808\n",
      "Function value obtained: -0.6935\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[6085.156387483277, 32, 549, 0.5615034595659859, 0.687068993857188] \n",
      "\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 42.2293\n",
      "Function value obtained: -0.7658\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[527.8639951731785, 126, 211, 0.6559446598566927, 0.2136833965403995] \n",
      "\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 40.9267\n",
      "Function value obtained: -0.4938\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 21 started. Evaluating function at random point.\n",
      "[2401.0940718920456, 9, 890, 0.38624213435838683, 0.7869097474436098] \n",
      "\n",
      "Iteration No: 21 ended. Evaluation done at random point.\n",
      "Time taken: 40.5758\n",
      "Function value obtained: -0.7744\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 22 started. Evaluating function at random point.\n",
      "[516.4918192816662, 67, 607, 0.8872747381523106, 0.11050227431280424] \n",
      "\n",
      "Iteration No: 22 ended. Evaluation done at random point.\n",
      "Time taken: 41.5897\n",
      "Function value obtained: -0.4931\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 23 started. Evaluating function at random point.\n",
      "[991.3297491328296, 4, 493, 0.7976039007456214, 0.15766059685439557] \n",
      "\n",
      "Iteration No: 23 ended. Evaluation done at random point.\n",
      "Time taken: 39.3349\n",
      "Function value obtained: -0.4937\n",
      "Current minimum: -0.7897\n",
      "Iteration No: 24 started. Evaluating function at random point.\n",
      "[513.5949263684475, 107, 851, 0.4108131224302622, 0.7866280661004899] \n",
      "\n",
      "Iteration No: 24 ended. Evaluation done at random point.\n",
      "Time taken: 40.3156\n",
      "Function value obtained: -0.8087\n",
      "Current minimum: -0.8087\n",
      "Iteration No: 25 started. Evaluating function at random point.\n",
      "[3492.930915544883, 56, 16, 0.7841021894386982, 0.23763684029862592] \n",
      "\n",
      "Iteration No: 25 ended. Evaluation done at random point.\n",
      "Time taken: 40.8850\n",
      "Function value obtained: -0.4903\n",
      "Current minimum: -0.8087\n",
      "Iteration No: 26 started. Evaluating function at random point.\n",
      "[1436.3750787644067, 24, 486, 0.7235903958932033, 0.523576726896179] \n",
      "\n",
      "Iteration No: 26 ended. Evaluation done at random point.\n",
      "Time taken: 42.7801\n",
      "Function value obtained: -0.5007\n",
      "Current minimum: -0.8087\n",
      "Iteration No: 27 started. Evaluating function at random point.\n",
      "[3382.0898454746575, 12, 97, 0.3055509986949366, 0.8485233301058951] \n",
      "\n",
      "Iteration No: 27 ended. Evaluation done at random point.\n",
      "Time taken: 40.4234\n",
      "Function value obtained: -0.7866\n",
      "Current minimum: -0.8087\n",
      "Iteration No: 28 started. Evaluating function at random point.\n",
      "[1266.6303277096226, 98, 506, 0.49885128610043944, 0.7684883470783824] \n",
      "\n",
      "Iteration No: 28 ended. Evaluation done at random point.\n",
      "Time taken: 41.3299\n",
      "Function value obtained: -0.7827\n",
      "Current minimum: -0.8087\n",
      "Iteration No: 29 started. Evaluating function at random point.\n",
      "[242.05394015116042, 118, 812, 0.2688446679539226, 0.5574227838105602] \n",
      "\n",
      "Iteration No: 29 ended. Evaluation done at random point.\n",
      "Time taken: 39.8172\n",
      "Function value obtained: -0.7187\n",
      "Current minimum: -0.8087\n",
      "Iteration No: 30 started. Evaluating function at random point.\n",
      "[261.29832351330134, 125, 138, 0.542918782070707, 0.2550505170069048] \n",
      "\n",
      "Iteration No: 30 ended. Evaluation done at random point.\n",
      "Time taken: 39.8364\n",
      "Function value obtained: -0.7624\n",
      "Current minimum: -0.8087\n"
     ]
    }
   ],
   "source": [
    "#buscando hiperparametros\n",
    "\n",
    "def treinar_modelo(params):\n",
    "    lrn_rate = params[0]\n",
    "    num_leaves = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    \n",
    "    print(params, '\\n')\n",
    "    \n",
    "    mdl_pipe = Pipeline([('scl', StandardScaler()),\n",
    "                        ('pca', PCA(n_components=150)),\n",
    "                        ('clf', LGBMClassifier(learning_rate=lrn_rate, num_leaves=num_leaves, min_child_samples=min_child_samples,\n",
    "                        subsample=subsample, colsample_bytree=colsample_bytree, random_state=0, subsample_freq=1, \n",
    "                         n_estimators=200))])\n",
    "    mdl_pipe.fit(X_train, y_train)\n",
    "    \n",
    "    p2 = mdl_pipe.predict_proba(X_test)[:,1] #.astype('int32')\n",
    "    \n",
    "    # Queremos minimizar o auc score\n",
    "    return -roc_auc_score(y_test, p2)\n",
    "\n",
    "# Definindo espaço de busca\n",
    "space = [(1e2, 1e4, 'log-uniform'), #learning rate\n",
    "         (2, 128), # num_leaves\n",
    "         (1, 1000), # min_child_samples\n",
    "         (0.05, 1.0), # subsample\n",
    "         (0.1, 1.0)] # colsample bytree\n",
    "\n",
    "# fazendo o fit do modelo com 30 calls\n",
    "resultado = dummy_minimize(treinar_modelo, space, random_state=1, verbose=1, n_calls=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
       "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
       "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
       "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
       "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
       "\n",
       "    var_8   var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  2.1337  8.8100  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1 -4.4131  5.9739  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  1.5233  8.3442  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  3.3755  7.4578  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  2.9890  7.1437  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_teste = db_teste.drop(['ID_code'], axis=1)\n",
    "db_teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_pipe = Pipeline([('scl', StandardScaler()),\n",
    "                        ('pca', PCA(n_components=150)),\n",
    "                        ('clf', LGBMClassifier(learning_rate=0.5949263684475, num_leaves=56, min_child_samples=16,\n",
    "                        subsample=0.7841021894386982, colsample_bytree=0.23763684029862592, random_state=0, subsample_freq=1, \n",
    "                         n_estimators=200))])\n",
    "mdl_pipe.fit(X_train, y_train)\n",
    "    \n",
    "p2 = mdl_pipe.predict_proba(X_test)[:,1]\n",
    "p3 = mdl_pipe.predict(db_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8228237633400535"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.009871192514273255, 120, 129, 0.9990884895579377, 0.3124800792567785] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 69.3337\n",
      "Function value obtained: -0.8245\n",
      "Current minimum: -0.8245\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.0006210998932353835, 51, 670, 0.9387621172657304, 0.8616798250174156] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 78.2258\n",
      "Function value obtained: -0.8497\n",
      "Current minimum: -0.8497\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.0004232013397179603, 68, 444, 0.2680983530433343, 0.5809725180523154] \n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 50.5854\n",
      "Function value obtained: -0.8449\n",
      "Current minimum: -0.8497\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.006728589742129336, 60, 431, 0.9421713999524447, 0.8005503127028804] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 77.7605\n",
      "Function value obtained: -0.8482\n",
      "Current minimum: -0.8497\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.0027035912483147407, 103, 94, 0.5422449214947946, 0.8785182267810853] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 79.5643\n",
      "Function value obtained: -0.8491\n",
      "Current minimum: -0.8497\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.004552959789286747, 107, 274, 0.1062810412364853, 0.7034752360620511] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 48.3415\n",
      "Function value obtained: -0.8496\n",
      "Current minimum: -0.8497\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.0015350800817657236, 87, 412, 0.23767335308554222, 0.3606666764912312] \n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 47.6160\n",
      "Function value obtained: -0.8369\n",
      "Current minimum: -0.8497\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.00019241559628256107, 101, 413, 0.0824627456265471, 0.661626987829618] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 42.5206\n",
      "Function value obtained: -0.8507\n",
      "Current minimum: -0.8507\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.002095421812724112, 40, 447, 0.2610183201586061, 0.16602775456833962] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 41.6346\n",
      "Function value obtained: -0.7986\n",
      "Current minimum: -0.8507\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.0008679147174590262, 14, 903, 0.163515944581681, 0.5723194391834011] \n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 41.7810\n",
      "Function value obtained: -0.8495\n",
      "Current minimum: -0.8507\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "[0.0001, 2, 1000, 0.05, 1.0] \n",
      "\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 36.9470\n",
      "Function value obtained: -0.8057\n",
      "Current minimum: -0.8507\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "[0.0001, 128, 1, 1.0, 0.4771599074919779] \n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 75.8268\n",
      "Function value obtained: -0.8321\n",
      "Current minimum: -0.8507\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "[0.0001, 2, 1000, 0.05, 0.8137819327167046] \n",
      "\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 37.0997\n",
      "Function value obtained: -0.7932\n",
      "Current minimum: -0.8507\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "[0.01, 128, 1000, 1.0, 1.0] \n",
      "\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 105.9413\n",
      "Function value obtained: -0.8478\n",
      "Current minimum: -0.8507\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "[0.01, 128, 1000, 1.0, 0.4381996644884899] \n",
      "\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 69.4043\n",
      "Function value obtained: -0.8343\n",
      "Current minimum: -0.8507\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "[0.01, 2, 1000, 1.0, 0.43031363112111676] \n",
      "\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.0057\n",
      "Function value obtained: -0.8324\n",
      "Current minimum: -0.8507\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "[0.0001, 128, 1, 1.0, 1.0] \n",
      "\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 110.9171\n",
      "Function value obtained: -0.8444\n",
      "Current minimum: -0.8507\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "[0.000612993495165126, 128, 1000, 0.05, 0.7242994569291666] \n",
      "\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 38.6244\n",
      "Function value obtained: -0.8544\n",
      "Current minimum: -0.8544\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "[0.01, 2, 1, 0.05, 1.0] \n",
      "\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 37.5044\n",
      "Function value obtained: -0.8521\n",
      "Current minimum: -0.8544\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "[0.0006192107948275486, 128, 1000, 0.05, 1.0] \n",
      "\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.1859\n",
      "Function value obtained: -0.8564\n",
      "Current minimum: -0.8564\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "[0.002358582162160045, 2, 740, 0.9810037819327356, 1.0] \n",
      "\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 47.8770\n",
      "Function value obtained: -0.8203\n",
      "Current minimum: -0.8564\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "[0.0012116343595013322, 128, 1, 0.05, 1.0] \n",
      "\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 68.9923\n",
      "Function value obtained: -0.8499\n",
      "Current minimum: -0.8564\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "[0.0006102650483315306, 128, 1, 1.0, 0.7178604020379734] \n",
      "\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 93.3149\n",
      "Function value obtained: -0.8404\n",
      "Current minimum: -0.8564\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "[0.01, 54, 1000, 0.05, 0.7514872902356257] \n",
      "\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 38.8108\n",
      "Function value obtained: -0.8542\n",
      "Current minimum: -0.8564\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "[0.01, 77, 1000, 0.05, 1.0] \n",
      "\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.7578\n",
      "Function value obtained: -0.8559\n",
      "Current minimum: -0.8564\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "[0.01, 51, 1000, 0.05, 0.732028312855129] \n",
      "\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.3190\n",
      "Function value obtained: -0.8541\n",
      "Current minimum: -0.8564\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "[0.00023252180197481112, 128, 1000, 0.05, 1.0] \n",
      "\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 38.8439\n",
      "Function value obtained: -0.8565\n",
      "Current minimum: -0.8565\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "[0.01, 2, 87, 0.05, 0.7123882677749224] \n",
      "\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 36.6591\n",
      "Function value obtained: -0.8449\n",
      "Current minimum: -0.8565\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "[0.01, 74, 807, 0.05, 1.0] \n",
      "\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.3438\n",
      "Function value obtained: -0.8551\n",
      "Current minimum: -0.8565\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "[0.0017637062085223618, 90, 1000, 0.05, 1.0] \n",
      "\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.1538\n",
      "Function value obtained: -0.8564\n",
      "Current minimum: -0.8565\n"
     ]
    }
   ],
   "source": [
    "space = [(1e-4, 1e-2, 'log-uniform'), #learning rate\n",
    "         (2, 128), # num_leaves\n",
    "         (1, 1000), # min_child_samples\n",
    "         (0.05, 1.0), # subsample\n",
    "         (0.1, 1.0)]\n",
    "\n",
    "resultados_gp = gp_minimize(treinar_modelo, space, random_state=1, verbose=1, n_calls=30, n_random_starts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_pipe = Pipeline([('scl', StandardScaler()),\n",
    "                        ('pca', PCA(n_components=150)),\n",
    "                        ('clf', LGBMClassifier(learning_rate=0.01, num_leaves=2, min_child_samples=87,\n",
    "                        subsample=0.05, colsample_bytree=0.7123882677749224, random_state=0, subsample_freq=1, \n",
    "                         n_estimators=200))])\n",
    "mdl_pipe.fit(X_train, y_train)\n",
    "    \n",
    "p2_xx = mdl_pipe.predict_proba(X_test)[:,1]\n",
    "p3_xx = mdl_pipe.predict(db_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8441653115744236"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, p2_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3xx_df = pd.DataFrame(p3_xx)\n",
    "p3xx_df['ID_code'] = db_teste_copy['ID_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>ID_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>test_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>test_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>test_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>test_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>test_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0 ID_code\n",
       "0  1  test_0\n",
       "1  1  test_1\n",
       "2  0  test_2\n",
       "3  1  test_3\n",
       "4  0  test_4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3xx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ID_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>test_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>test_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>test_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>test_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>test_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target ID_code\n",
       "0       1  test_0\n",
       "1       1  test_1\n",
       "2       0  test_2\n",
       "3       1  test_3\n",
       "4       0  test_4"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3xx_df = p3xx_df.rename(columns={0: 'target'})\n",
    "p3xx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3xx_df.to_csv(r'./chal_testxx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
